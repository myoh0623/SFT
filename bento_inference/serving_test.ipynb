{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import bentoml\n",
    "import PIL.Image as Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2004/3638141814.py:5: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  predict_data = user_input_image[np.newaxis, ...].tolist()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "user_input_image = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
    "user_input_image = Image.open(user_input_image).resize(IMAGE_SHAPE)\n",
    "user_input_image = np.array(user_input_image)/255.0\n",
    "predict_data = user_input_image[np.newaxis, ...].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Runner.init_local' is for debugging and testing only. Make sure to remove it before deploying to production.\n",
      "/home/user/anaconda3/envs/bentoml/lib/python3.10/typing.py:1415: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  for base in cls.__mro__[:-1]:  # without object\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19967595  1.0678965  -0.09609853 ...  0.10602828 -0.56032073\n",
      "  -0.07089337]]\n"
     ]
    }
   ],
   "source": [
    "mobilenet_runner = bentoml.tensorflow.get(\"mobilenet:0.1\").to_runner()\n",
    "mobilenet_runner.init_local()\n",
    "result = mobilenet_runner.run(predict_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_model import postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted': '[ 0.19967595  1.0678965  -0.09609853 ...  0.10602828 -0.56032073\\n -0.07089337]', 'class': 'military uniform'}\n"
     ]
    }
   ],
   "source": [
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "predicted_class_name = postprocessing(predicted_class)\n",
    "result = {\"predicted\":str(result[0]), \"class\":predicted_class_name}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "user_input_image = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
    "user_input_image = Image.open(user_input_image).resize(IMAGE_SHAPE)\n",
    "user_input_image = np.array(user_input_image)/255.0\n",
    "predict_data = user_input_image[np.newaxis, ...].tolist()\n",
    "\n",
    "mobilenet_runner = bentoml.tensorflow.get(\"mobilenet:0.1\").to_runner()\n",
    "mobilenet_runner.init_local()\n",
    "result = mobilenet_runner.run(predict_data)\n",
    "print(result)\n",
    "\n",
    "from load_model import postprocessing\n",
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "predicted_class_name = postprocessing(predicted_class)\n",
    "result = {\"predicted\":str(result[0]), \"class\":predicted_class_name}\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "import tensorflow as tf\n",
    "import bentoml\n",
    "from PIL.Image import Image as PILImage\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# from bentoml.io import NumpyNdarray\n",
    "from bentoml.io import JSON\n",
    "from bentoml.io import \n",
    "\n",
    "\n",
    "\n",
    "mobilenet_runner = bentoml.tensorflow.get(\"mobilenet:0.1\").to_runner()\n",
    "# mobilenet_runner.init_local()\n",
    "svc = bentoml.Service( name=\"mobilenet\", runners=[mobilenet_runner] )\n",
    "\n",
    "def postprocessing(predicted_class):\n",
    "    imagenet_labels = np.array(open('./ImageNetLabels.txt').read().splitlines())\n",
    "    predicted_class_name = imagenet_labels[predicted_class]\n",
    "    return predicted_class_name\n",
    "\n",
    "\n",
    "@svc.api(input=Image(), output=JSON())\n",
    "async def predict(f: PILImage) -> \"JSON\":\n",
    "    assert isinstance(f, PILImage)\n",
    "    # IMAGE_SHAPE = (224, 224)\n",
    "    # image = np.array(f.resize(IMAGE_SHAPE)).astype(\"float32\")\n",
    "    # user_input_image = f.resize(IMAGE_SHAPE)\n",
    "    # user_input_image = np.array(user_input_image)/255.0\n",
    "    # predict_data = user_input_image[np.newaxis, ...].tolist()\n",
    "    result = await mobilenet_runner.async_run(predict_data) # 추론하는 code \n",
    "    predicted_class = np.argmax(result[0], axis=-1) # 가장 높은 확률 출력 \n",
    "    class_name = postprocessing(predicted_class) # class 로 변경 \n",
    "    return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 11:16:20.791821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 11:16:22.040069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 11:16:22.040196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 11:16:22.040225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-16T11:16:23+0900 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service.py:svc\" can be accessed at http://localhost:5002/metrics.\n",
      "2023-03-16T11:16:24+0900 [INFO] [cli] Starting development HTTP BentoServer from \"service.py:svc\" listening on http://0.0.0.0:5002 (Press CTRL+C to quit)\n",
      "2023-03-16 11:16:24 circus[9224] [INFO] Loading the plugin...\n",
      "2023-03-16 11:16:24 circus[9224] [INFO] Endpoint: 'tcp://127.0.0.1:58523'\n",
      "2023-03-16 11:16:24 circus[9224] [INFO] Pub/sub: 'tcp://127.0.0.1:55913'\n",
      "2023-03-16T11:16:24+0900 [INFO] [observer] Watching directories: ['/home/user/SFT/bento_inference', '/home/user/bentoml/models']\n",
      "2023-03-16 11:16:25.038083: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 11:16:26.293794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 11:16:26.293924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 11:16:26.293955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-16 11:16:27.714101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-16 11:16:27.714191: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-16 11:16:27.714220: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (M30523): /proc/driver/nvidia/version does not exist\n",
      "2023-03-16 11:16:27.714734: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16T11:16:32+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:47358 (scheme=http,method=GET,path=/,type=,length=) (status=200,type=text/html; charset=utf-8,length=2859) 1.285ms (trace=8d56e698f6a6f00b50394ca979688f10,span=508607bcc64878f4,sampled=0)\n",
      "2023-03-16T11:16:32+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:47358 (scheme=http,method=GET,path=/docs.json,type=,length=) (status=200,type=application/json,length=5977) 15.139ms (trace=8f2d820f5d57acf7bb3cf506ff1debea,span=a71d759b29989b0a,sampled=0)\n",
      "2023-03-16T11:16:50+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:47360 (scheme=http,method=POST,path=/predict,type=image/jp2,length=93198) (status=200,type=application/json,length=7) 9784.728ms (trace=1bf80f39d63eb38ed85469c17a20c262,span=b0bcc9f5786334df,sampled=0)\n",
      "2023-03-16T11:18:47+0900 [ERROR] [dev_api_server:mobilenet] Exception on /predict [POST] (trace=88d1101a6a9e8e2a707375813a1e5604,span=433ad2ebad96d17a,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/server/http_app.py\", line 311, in api_func\n",
      "    input_data = await api.input.from_http_request(request)\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/io_descriptors/image.py\", line 318, in from_http_request\n",
      "    content_type, _ = parse_options_header(request.headers[\"content-type\"])\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/starlette/datastructures.py\", line 568, in __getitem__\n",
      "    raise KeyError(key)\n",
      "KeyError: 'content-type'\n",
      "2023-03-16T11:18:47+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:54618 (scheme=http,method=POST,path=/predict,type=,length=46998) (status=500,type=application/json,length=110) 4.090ms (trace=88d1101a6a9e8e2a707375813a1e5604,span=433ad2ebad96d17a,sampled=0)\n",
      "2023-03-16T11:23:31+0900 [ERROR] [dev_api_server:mobilenet] Exception on /predict [POST] (trace=e663b5e6c2f86beb6c0c9200d50b3184,span=c669d5b0725cb79a,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/server/http_app.py\", line 311, in api_func\n",
      "    input_data = await api.input.from_http_request(request)\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/io_descriptors/image.py\", line 367, in from_http_request\n",
      "    raise BadInput(\n",
      "bentoml.exceptions.BadInput: mime type application/json is not allowed, allowed mime types are: image/jp2, image/x-tga, image/vnd.adobe.photoshop, image/mpo, image/xbm, image/x-portable-anymap, image/png, image/icns, image/x-icon, image/tiff, image/x-pcx, image/bmp, image/jpeg, image/gif, image/sgi, image/xpm, video/mpeg, application/postscript, image/webp\n",
      "2023-03-16T11:23:31+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:41540 (scheme=http,method=POST,path=/predict,type=application/json,length=46998) (status=400,type=application/json,length=372) 0.930ms (trace=e663b5e6c2f86beb6c0c9200d50b3184,span=c669d5b0725cb79a,sampled=0)\n",
      "2023-03-16T11:25:39+0900 [ERROR] [dev_api_server:mobilenet] Exception on /predict [POST] (trace=39ba36525bb4fc0506c872cbd58c3fda,span=be80340c7424f3bb,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/server/http_app.py\", line 311, in api_func\n",
      "    input_data = await api.input.from_http_request(request)\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/io_descriptors/image.py\", line 367, in from_http_request\n",
      "    raise BadInput(\n",
      "bentoml.exceptions.BadInput: mime type application/json is not allowed, allowed mime types are: image/jp2, image/x-tga, image/vnd.adobe.photoshop, image/mpo, image/xbm, image/x-portable-anymap, image/png, image/icns, image/x-icon, image/tiff, image/x-pcx, image/bmp, image/jpeg, image/gif, image/sgi, image/xpm, video/mpeg, application/postscript, image/webp\n",
      "2023-03-16T11:25:39+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:48452 (scheme=http,method=POST,path=/predict,type=application/json,length=93198) (status=400,type=application/json,length=372) 2.347ms (trace=39ba36525bb4fc0506c872cbd58c3fda,span=be80340c7424f3bb,sampled=0)\n",
      "2023-03-16T11:25:49+0900 [ERROR] [dev_api_server:mobilenet] Exception on /predict [POST] (trace=70614921bc86ef5c56cf9f04f308da8c,span=1054cd6ff33b9d28,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/server/http_app.py\", line 311, in api_func\n",
      "    input_data = await api.input.from_http_request(request)\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/io_descriptors/image.py\", line 367, in from_http_request\n",
      "    raise BadInput(\n",
      "bentoml.exceptions.BadInput: mime type application/json is not allowed, allowed mime types are: image/jp2, image/x-tga, image/vnd.adobe.photoshop, image/mpo, image/xbm, image/x-portable-anymap, image/png, image/icns, image/x-icon, image/tiff, image/x-pcx, image/bmp, image/jpeg, image/gif, image/sgi, image/xpm, video/mpeg, application/postscript, image/webp\n",
      "2023-03-16T11:25:49+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:48960 (scheme=http,method=POST,path=/predict,type=application/json,length=93198) (status=400,type=application/json,length=372) 1.836ms (trace=70614921bc86ef5c56cf9f04f308da8c,span=1054cd6ff33b9d28,sampled=0)\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service.py:svc --reload -p 5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "import tensorflow as tf\n",
    "import bentoml\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "from bentoml.io import NumpyNdarray, JSON\n",
    "\n",
    "TYPE_CHECKING = True\n",
    "if TYPE_CHECKING:\n",
    "    from numpy.typing import NDArray\n",
    "\n",
    "\n",
    "mobilenet_runner = bentoml.tensorflow.get(\"mobilenet:0.1\").to_runner()\n",
    "# mobilenet_runner.init_local()\n",
    "svc = bentoml.Service( name=\"mobilenet\", runners=[mobilenet_runner] )\n",
    "\n",
    "def postprocessing(predicted_class):\n",
    "    imagenet_labels = np.array(open('./ImageNetLabels.txt').read().splitlines())\n",
    "    predicted_class_name = imagenet_labels[predicted_class]\n",
    "    return predicted_class_name\n",
    "\n",
    "\n",
    "@svc.api(input=NumpyNdarray(), output=JSON())\n",
    "async def predict(input_arr: NDArray[any]) -> NDArray[any]:\n",
    "    predict_data = input_arr.tolist()\n",
    "    result = await mobilenet_runner.async_run(predict_data) # 추론하는 code\n",
    "    predicted_class = np.argmax(result[0], axis=-1) # 가장 높은 확률 출력 \n",
    "    predicted_class_name = postprocessing(predicted_class) # class 로 변경\n",
    "    result = {\"predicted\":str(result[0]), \"class\":predicted_class_name}\n",
    "    print(result)\n",
    "    return result\n",
    "    # return input_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-17 11:08:27.273373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 11:08:28.358632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-17 11:08:28.358729: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-17 11:08:28.358756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-17T11:08:29+0900 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service.py:svc\" can be accessed at http://localhost:5002/metrics.\n",
      "2023-03-17T11:08:30+0900 [INFO] [cli] Starting development HTTP BentoServer from \"service.py:svc\" listening on http://0.0.0.0:5002 (Press CTRL+C to quit)\n",
      "2023-03-17 11:08:30 circus[2331] [INFO] Loading the plugin...\n",
      "2023-03-17 11:08:30 circus[2331] [INFO] Endpoint: 'tcp://127.0.0.1:54443'\n",
      "2023-03-17 11:08:30 circus[2331] [INFO] Pub/sub: 'tcp://127.0.0.1:39477'\n",
      "2023-03-17T11:08:30+0900 [INFO] [observer] Watching directories: ['/home/user/SFT/bento_inference', '/home/user/bentoml/models']\n",
      "2023-03-17 11:08:30.945869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17 11:08:32.155893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-17 11:08:32.155980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-17 11:08:32.156007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-17 11:08:33.486976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-17 11:08:33.487032: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-17 11:08:33.487088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (M30523): /proc/driver/nvidia/version does not exist\n",
      "2023-03-17 11:08:33.487443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-17T11:08:45+0900 [ERROR] [dev_api_server:mobilenet] Exception on /predict [POST] (trace=ff3025694f2d47aaa37b31931330524d,span=e92e6e63f5a1de03,sampled=0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/server/http_app.py\", line 311, in api_func\n",
      "    input_data = await api.input.from_http_request(request)\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/bentoml/_internal/io_descriptors/numpy.py\", line 401, in from_http_request\n",
      "    obj = await request.json()\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/site-packages/starlette/requests.py\", line 244, in json\n",
      "    self._json = json.loads(body)\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/json/__init__.py\", line 346, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/user/anaconda3/envs/bentoml/lib/python3.10/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "2023-03-17T11:08:45+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:41406 (scheme=http,method=POST,path=/predict,type=application/json,length=) (status=500,type=application/json,length=110) 2.786ms (trace=ff3025694f2d47aaa37b31931330524d,span=e92e6e63f5a1de03,sampled=0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service.py:svc --reload -p 5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bentoml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e06c26114b0c5c9844c0b36fe00c64521365963762b9729f92cfb84c5d4b193"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
