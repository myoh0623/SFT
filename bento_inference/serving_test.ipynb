{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import bentoml\n",
    "import PIL.Image as Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2004/3638141814.py:5: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  predict_data = user_input_image[np.newaxis, ...].tolist()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "user_input_image = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
    "user_input_image = Image.open(user_input_image).resize(IMAGE_SHAPE)\n",
    "user_input_image = np.array(user_input_image)/255.0\n",
    "predict_data = user_input_image[np.newaxis, ...].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Runner.init_local' is for debugging and testing only. Make sure to remove it before deploying to production.\n",
      "/home/user/anaconda3/envs/bentoml/lib/python3.10/typing.py:1415: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  for base in cls.__mro__[:-1]:  # without object\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19967595  1.0678965  -0.09609853 ...  0.10602828 -0.56032073\n",
      "  -0.07089337]]\n"
     ]
    }
   ],
   "source": [
    "mobilenet_runner = bentoml.tensorflow.get(\"mobilenet:0.1\").to_runner()\n",
    "mobilenet_runner.init_local()\n",
    "result = mobilenet_runner.run(predict_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_model import postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted': '[ 0.19967595  1.0678965  -0.09609853 ...  0.10602828 -0.56032073\\n -0.07089337]', 'class': 'military uniform'}\n"
     ]
    }
   ],
   "source": [
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "predicted_class_name = postprocessing(predicted_class)\n",
    "result = {\"predicted\":str(result[0]), \"class\":predicted_class_name}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "user_input_image = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
    "user_input_image = Image.open(user_input_image).resize(IMAGE_SHAPE)\n",
    "user_input_image = np.array(user_input_image)/255.0\n",
    "predict_data = user_input_image[np.newaxis, ...].tolist()\n",
    "\n",
    "mobilenet_runner = bentoml.tensorflow.get(\"mobilenet:0.1\").to_runner()\n",
    "mobilenet_runner.init_local()\n",
    "result = mobilenet_runner.run(predict_data)\n",
    "print(result)\n",
    "\n",
    "from load_model import postprocessing\n",
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "predicted_class_name = postprocessing(predicted_class)\n",
    "result = {\"predicted\":str(result[0]), \"class\":predicted_class_name}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "import tensorflow as tf\n",
    "import bentoml\n",
    "from PIL.Image import Image as PILImage\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# from bentoml.io import NumpyNdarray\n",
    "from bentoml.io import JSON\n",
    "from bentoml.io import Image\n",
    "\n",
    "\n",
    "\n",
    "mobilenet_runner = bentoml.tensorflow.get(\"mobilenet:0.1\").to_runner()\n",
    "# mobilenet_runner.init_local()\n",
    "svc = bentoml.Service( name=\"mobilenet\", runners=[mobilenet_runner] )\n",
    "\n",
    "def postprocessing(predicted_class):\n",
    "    imagenet_labels = np.array(open('./ImageNetLabels.txt').read().splitlines())\n",
    "    predicted_class_name = imagenet_labels[predicted_class]\n",
    "    return predicted_class_name\n",
    "\n",
    "\n",
    "@svc.api(input=Image(), output=JSON())\n",
    "async def predict(f: PILImage) -> \"JSON\":\n",
    "    assert isinstance(f, PILImage)\n",
    "    IMAGE_SHAPE = (224, 224)\n",
    "    image = np.array(f.resize(IMAGE_SHAPE)).astype(\"float32\")\n",
    "    user_input_image = f.resize(IMAGE_SHAPE)\n",
    "    user_input_image = np.array(user_input_image)/255.0\n",
    "    predict_data = user_input_image[np.newaxis, ...].tolist()\n",
    "    result = await mobilenet_runner.async_run(predict_data) # 추론하는 code \n",
    "    predicted_class = np.argmax(result[0], axis=-1) # 가장 높은 확률 출력 \n",
    "    class_name = postprocessing(predicted_class) # class 로 변경 \n",
    "    return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-16 10:56:19.332474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 10:56:20.514553: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 10:56:20.514659: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 10:56:20.514698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-16T10:56:21+0900 [INFO] [cli] Prometheus metrics for HTTP BentoServer from \"service.py:svc\" can be accessed at http://localhost:5002/metrics.\n",
      "2023-03-16T10:56:22+0900 [INFO] [cli] Starting development HTTP BentoServer from \"service.py:svc\" listening on http://0.0.0.0:5002 (Press CTRL+C to quit)\n",
      "2023-03-16 10:56:23 circus[8820] [INFO] Loading the plugin...\n",
      "2023-03-16 10:56:23 circus[8820] [INFO] Endpoint: 'tcp://127.0.0.1:45821'\n",
      "2023-03-16 10:56:23 circus[8820] [INFO] Pub/sub: 'tcp://127.0.0.1:44463'\n",
      "2023-03-16 10:56:23.103184: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16T10:56:23+0900 [INFO] [observer] Watching directories: ['/home/user/SFT/bento_inference', '/home/user/bentoml/models']\n",
      "2023-03-16 10:56:24.279455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 10:56:24.279579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-16 10:56:24.279607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-16 10:56:25.599890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-16 10:56:25.599976: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-16 10:56:25.599999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (M30523): /proc/driver/nvidia/version does not exist\n",
      "2023-03-16 10:56:25.600502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16T10:56:43+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:40238 (scheme=http,method=GET,path=/,type=,length=) (status=200,type=text/html; charset=utf-8,length=2859) 0.792ms (trace=cdf8d168abe4816e349d3f3c540c7fe5,span=8fa5c7a94faa2526,sampled=0)\n",
      "2023-03-16T10:56:46+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:40238 (scheme=http,method=GET,path=/,type=,length=) (status=200,type=text/html; charset=utf-8,length=2859) 0.419ms (trace=3f7487345044b2e1a4d1f3c830560dd2,span=768bdca3e7ee0962,sampled=0)\n",
      "2023-03-16T10:56:46+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:40238 (scheme=http,method=GET,path=/docs.json,type=,length=) (status=200,type=application/json,length=5977) 24.429ms (trace=b8d1719bfee3ebd5205d6a39adf3fc63,span=e2960de50e60b75f,sampled=0)\n",
      "2023-03-16T10:57:31+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:40240 (scheme=http,method=POST,path=/predict,type=image/jpeg,length=46998) (status=200,type=application/json,length=6) 10050.837ms (trace=0a0e1adbc21030cebc5861875378ba64,span=103744454994fd34,sampled=0)\n",
      "2023-03-16T10:58:00+0900 [INFO] [dev_api_server:mobilenet] 127.0.0.1:43860 (scheme=http,method=POST,path=/predict,type=image/jpeg,length=93198) (status=200,type=application/json,length=7) 9896.624ms (trace=1c6ab1f1da2173a607047e562e38eb51,span=32da10137bdd390f,sampled=0)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve service.py:svc --reload -p 5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bentoml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e06c26114b0c5c9844c0b36fe00c64521365963762b9729f92cfb84c5d4b193"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
